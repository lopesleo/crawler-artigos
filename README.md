
# ğŸ“° Crawler de Artigos

Este projeto Ã© um crawler de artigos que coleta artigos de um site especÃ­fico e salva o conteÃºdo em arquivos de texto.

## ğŸ› ï¸ Requisitos

- Python 3.x
- `python-dotenv` para carregar variÃ¡veis de ambiente de um arquivo `.env`

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
   ```sh
   git clone https://github.com/lopesleo/crawler-artigos.git
   cd crawler-artigos
   ```

2. Crie um ambiente virtual e ative-o:
   ```sh
   python -m venv venv
   venv\Scripts\activate  # No Windows
   # ou
   source venv/bin/activate  # No Linux/Mac
   ```

3. Instale as dependÃªncias:
   ```sh
   pip install -r requirements.txt
   ```

4. Crie um arquivo `.env` na raiz do projeto e adicione as seguintes variÃ¡veis:
   ```
   URL_ARTIGOS=xxxx
   NOME_PASTA=artigos
   ```

## ğŸ“– Uso

1. Execute o script principal:
   ```sh
   python main.py
   ```

2. O script irÃ¡ coletar os artigos do site especificado na variÃ¡vel `URL_ARTIGOS` e salvar o conteÃºdo em arquivos de texto na pasta especificada pela variÃ¡vel `NOME_PASTA`.

## ğŸ—‚ï¸ Estrutura do Projeto

- `main.py`: Script principal que executa o crawler.
- `robot.py`: ContÃ©m a classe `Robot` que lida com a navegaÃ§Ã£o e coleta de artigos.
- `utils/fileutils.py`: ContÃ©m funÃ§Ãµes utilitÃ¡rias para manipulaÃ§Ã£o de arquivos e pastas.
- `.env`: Arquivo de configuraÃ§Ã£o com variÃ¡veis de ambiente.

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um fork do projeto.
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`).
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`).
4. FaÃ§a push para a branch (`git push origin feature/nova-feature`).
5. Crie um novo Pull Request.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

